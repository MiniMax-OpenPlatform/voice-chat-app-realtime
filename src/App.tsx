import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Message, VOICE_OPTIONS, ConnectionStatus } from './types';
import { RealtimeService } from './services/realtimeService';
import { AudioProcessor } from './services/audioProcessor';
import './App.css';

// é»˜è®¤ç³»ç»Ÿæç¤ºè¯
const DEFAULT_SYSTEM_PROMPT = `ä½ æ˜¯ä¸€ä½å‹å–„ã€ä¸“ä¸šçš„è‹±è¯­å­¦ä¹ è¾…åŠ©åŠ©æ‰‹ï¼Œè‡´åŠ›äºå¸®åŠ©ç”¨æˆ·æå‡è‹±è¯­è¡¨è¾¾èƒ½åŠ›ã€‚ä½ çš„æ ¸å¿ƒèŒè´£åŒ…æ‹¬ï¼š

ã€è¯„æµ‹ç»´åº¦ã€‘
é’ˆå¯¹ç”¨æˆ·çš„æ¯ä¸€è½®è‹±è¯­å¯¹è¯å†…å®¹ï¼Œè¯·ä»ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦è¿›è¡Œè¯„ä¼°ï¼š

1. è¯­æ³•å‡†ç¡®æ€§ï¼ˆGrammar Accuracyï¼‰ï¼š
   - ä»”ç»†æ£€æŸ¥è¯­æ³•é”™è¯¯ï¼ˆæ—¶æ€ã€ä¸»è°“ä¸€è‡´ã€å† è¯ä½¿ç”¨ã€ä»‹è¯æ­é…ç­‰ï¼‰
   - å¦‚æœ‰é”™è¯¯ï¼šæ¸©å’Œåœ°æŒ‡å‡ºå…·ä½“é—®é¢˜ï¼Œå¹¶ç®€è¦è¯´æ˜æ­£ç¡®ç”¨æ³•
   - å¦‚æ— é”™è¯¯ï¼šç»™äºˆè‚¯å®šé¼“åŠ±

2. è¡¨è¾¾åœ°é“æ€§ï¼ˆExpression Authenticityï¼‰ï¼š
   - åˆ¤æ–­ç”¨è¯å’Œå¥å¼æ˜¯å¦ç¬¦åˆè‹±è¯­æ¯è¯­è€…çš„è¡¨è¾¾ä¹ æƒ¯
   - å¦‚å¯ä¼˜åŒ–ï¼šæä¾›1-2ä¸ªæ›´åœ°é“ã€è‡ªç„¶çš„è¡¨è¾¾æ–¹å¼ä¾›å‚è€ƒ

3. ç»¼åˆè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰ï¼š
   - æ ¹æ®è¯­æ³•å‡†ç¡®æ€§ã€è¯æ±‡ä¸°å¯Œåº¦ã€è¡¨è¾¾æµç•…åº¦ç»¼åˆæ‰“åˆ†

ã€åé¦ˆé£æ ¼ã€‘
- ä¿æŒé¼“åŠ±å’Œæ­£é¢çš„æ€åº¦
- å»ºè®®è¦å…·ä½“ã€å¯æ“ä½œ
- è¯­è¨€ç®€æ´å‹å¥½

ã€äº’åŠ¨å¼•å¯¼ã€‘
åœ¨å®Œæˆè¯„æµ‹åé¦ˆåï¼Œè¯·ä¸»åŠ¨æå‡ºä¸€ä¸ªç›¸å…³çš„å¼€æ”¾æ€§é—®é¢˜æ¥å»¶ç»­å¯¹è¯ã€‚

è®°ä½ï¼šä½ çš„ç›®æ ‡æ˜¯è®©å­¦ä¹ è¿‡ç¨‹è½»æ¾æ„‰å¿«ï¼Œåœ¨çº æ­£é”™è¯¯çš„åŒæ—¶ä¿æŠ¤ç”¨æˆ·çš„å­¦ä¹ çƒ­æƒ…ã€‚`;

const App: React.FC = () => {
  // ==================== çŠ¶æ€ ====================
  const [messages, setMessages] = useState<Message[]>([]);
  const [connectionStatus, setConnectionStatus] = useState<ConnectionStatus>('disconnected');
  const [isConversationMode, setIsConversationMode] = useState(false);  // æŒç»­å¯¹è¯æ¨¡å¼
  const [isListening, setIsListening] = useState(false);  // æ­£åœ¨ç›‘å¬ç”¨æˆ·è¯´è¯
  const [isResponding, setIsResponding] = useState(false);
  const [streamingText, setStreamingText] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [selectedVoice, setSelectedVoice] = useState('male-qn-qingse');
  const [volume, setVolume] = useState(0);  // éº¦å…‹é£éŸ³é‡

  // é…ç½®çŠ¶æ€
  const [apiKey, setApiKey] = useState(process.env.REACT_APP_API_KEY || '');
  const [systemPrompt, setSystemPrompt] = useState(DEFAULT_SYSTEM_PROMPT);
  const [showSettings, setShowSettings] = useState(false);  // è®¾ç½®é¢æ¿æ˜¾ç¤º

  // ==================== Refs ====================
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const realtimeRef = useRef<RealtimeService | null>(null);
  const audioProcessorRef = useRef<AudioProcessor | null>(null);
  const streamingTextRef = useRef('');
  const isInterruptedRef = useRef(false);  // æ‰“æ–­æ ‡å¿—ï¼Œç”¨äºå¿½ç•¥åç»­éŸ³é¢‘æ•°æ®
  const isConversationModeRef = useRef(false);  // å¯¹è¯æ¨¡å¼ refï¼ˆç”¨äºå›è°ƒä¸­è®¿é—®æœ€æ–°çŠ¶æ€ï¼‰
  const hasSpeechRef = useRef(false);  // æœ¬è½®æ˜¯å¦æœ‰è¯´è¯

  // ==================== è¾…åŠ©å‡½æ•° ====================
  const addMessage = useCallback((role: 'user' | 'assistant', content: string, isAudio = false) => {
    const message: Message = {
      id: Date.now().toString() + Math.random().toString(36).substr(2, 9),
      role,
      content,
      timestamp: new Date(),
      isAudio,
    };
    setMessages((prev) => [...prev, message]);
  }, []);

  const clearError = useCallback(() => {
    setError(null);
  }, []);

  // å¯åŠ¨éº¦å…‹é£ç›‘å¬
  const startListening = useCallback(async () => {
    if (!audioProcessorRef.current || !realtimeRef.current?.isConnectedState()) return;

    try {
      hasSpeechRef.current = false;
      audioProcessorRef.current.resetVADState();
      await audioProcessorRef.current.startCapture((base64) => {
        realtimeRef.current?.appendAudio(base64);
      });
      setIsListening(true);
      console.log('ğŸ‘‚ å¼€å§‹ç›‘å¬...');
    } catch (err: any) {
      setError(err.message);
    }
  }, []);

  // ç”¨äºåœ¨å›è°ƒä¸­è°ƒç”¨æœ€æ–°ç‰ˆæœ¬çš„ startListening
  const startListeningRef = useRef(startListening);
  startListeningRef.current = startListening;

  // åœæ­¢éº¦å…‹é£ç›‘å¬
  const stopListening = useCallback(() => {
    if (!audioProcessorRef.current) return;
    audioProcessorRef.current.stopCapture();
    setIsListening(false);
    setVolume(0);
    console.log('ğŸ”‡ åœæ­¢ç›‘å¬');
  }, []);

  // å¤„ç†ç”¨æˆ·è¯´è¯ç»“æŸï¼ˆVAD æ£€æµ‹åˆ°é™éŸ³ï¼‰- ä½¿ç”¨ ref å­˜å‚¨
  const handleSpeechEndRef = useRef(() => {});
  handleSpeechEndRef.current = () => {
    if (!isConversationModeRef.current || !hasSpeechRef.current) return;

    // å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œä¸å¤„ç†é™éŸ³ç»“æŸï¼ˆç­‰å¾…ç”¨æˆ·ç»§ç»­è¯´è¯æˆ–æ‰“æ–­å®Œæˆï¼‰
    if (isRespondingRef.current) return;

    console.log('ğŸ“¤ é™éŸ³è¶…æ—¶ï¼Œæäº¤éŸ³é¢‘å¹¶è§¦å‘å“åº”');
    // ä¸åœæ­¢ç›‘å¬ï¼ä¿æŒéº¦å…‹é£å¼€å¯ä»¥ä¾¿æ£€æµ‹æ‰“æ–­
    // stopListening();

    // é‡ç½®è¯´è¯çŠ¶æ€ï¼Œå‡†å¤‡ä¸‹ä¸€è½®
    hasSpeechRef.current = false;
    audioProcessorRef.current?.resetVADState();

    // æäº¤éŸ³é¢‘å¹¶è§¦å‘å“åº”
    realtimeRef.current?.commitAudio();
    realtimeRef.current?.createResponse();
  };

  // å¤„ç†ç”¨æˆ·å¼€å§‹è¯´è¯ï¼ˆVAD æ£€æµ‹åˆ°å£°éŸ³ï¼‰- ä½¿ç”¨ ref å­˜å‚¨
  const isRespondingRef = useRef(false);
  isRespondingRef.current = isResponding;
  const isListeningRef = useRef(false);
  isListeningRef.current = isListening;

  const handleSpeechStartRef = useRef(() => {});
  handleSpeechStartRef.current = () => {
    hasSpeechRef.current = true;

    // å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œè‡ªåŠ¨æ‰“æ–­
    if (isRespondingRef.current) {
      console.log('ğŸ›‘ ç”¨æˆ·å¼€å§‹è¯´è¯ï¼Œè‡ªåŠ¨æ‰“æ–­ AI');
      isInterruptedRef.current = true;
      audioProcessorRef.current?.stopPlayback();
      realtimeRef.current?.interrupt();
      // æ¸…ç©ºä¹‹å‰çš„éŸ³é¢‘ç¼“å†²åŒºï¼Œé‡æ–°å¼€å§‹
      realtimeRef.current?.clearAudioBuffer();
      setIsResponding(false);
      setStreamingText('');
      streamingTextRef.current = '';
      // é‡ç½® hasSpeechï¼Œè®©æ–°çš„è¯­éŸ³è¾“å…¥é‡æ–°å¼€å§‹è®¡ç®—
      hasSpeechRef.current = true;
    }
  };

  // ==================== åˆå§‹åŒ–æœåŠ¡ ====================
  const initializeService = useCallback((key: string, prompt: string, voice: string) => {
    // æ¸…ç†æ—§æœåŠ¡
    if (realtimeRef.current) {
      realtimeRef.current.disconnect();
    }
    if (audioProcessorRef.current) {
      audioProcessorRef.current.destroy();
    }

    // åˆå§‹åŒ–æ–°æœåŠ¡
    realtimeRef.current = new RealtimeService({
      apiKey: key,
      voice: voice,
      instructions: prompt,
    });

    audioProcessorRef.current = new AudioProcessor();

    // è®¾ç½® VAD å›è°ƒ
    audioProcessorRef.current.setVADCallbacks({
      onSpeechStart: () => handleSpeechStartRef.current(),
      onSpeechEnd: () => handleSpeechEndRef.current(),
      onVolumeChange: (vol) => setVolume(vol),
    });

    // è®¾ç½® Realtime å›è°ƒ
    setupRealtimeCallbacks();

    console.log('âœ… æœåŠ¡å·²åˆå§‹åŒ–');
  }, []);

  // è®¾ç½® Realtime å›è°ƒ
  const setupRealtimeCallbacks = useCallback(() => {
    if (!realtimeRef.current) return;

    realtimeRef.current.setCallbacks({
      onConnected: () => {
        setConnectionStatus('connected');
        setError(null);
        console.log('âœ… å·²è¿æ¥åˆ° Realtime API');
      },

      onDisconnected: () => {
        setConnectionStatus('disconnected');
        isConversationModeRef.current = false;
        setIsConversationMode(false);
        setIsListening(false);
        setIsResponding(false);
      },

      onUserTranscript: (transcript) => {
        console.log('ğŸ¤ ç”¨æˆ·è¯­éŸ³:', transcript);
        addMessage('user', transcript, true);
      },

      onResponseStart: () => {
        isInterruptedRef.current = false;
        setIsResponding(true);
        setStreamingText('');
        streamingTextRef.current = '';
      },

      onTextDelta: (delta) => {
        if (isInterruptedRef.current) return;
        setIsResponding(true);
        streamingTextRef.current += delta;
        setStreamingText(streamingTextRef.current);
      },

      onTextDone: (text) => {
        if (isInterruptedRef.current) return;
        addMessage('assistant', text);
        setStreamingText('');
        streamingTextRef.current = '';
      },

      onAudioDelta: (audioBase64) => {
        if (isInterruptedRef.current) return;
        setIsResponding(true);
        audioProcessorRef.current?.playAudioChunk(audioBase64);
      },

      onAudioDone: () => {
        console.log('ğŸ”Š AI éŸ³é¢‘æµæ¥æ”¶å®Œæˆ');
        const checkPlaybackDone = () => {
          if (!audioProcessorRef.current?.isCurrentlyPlaying()) {
            console.log('ğŸ”Š AI éŸ³é¢‘æ’­æ”¾å®Œæˆ');
            if (!isInterruptedRef.current) {
              setIsResponding(false);
            }
            isInterruptedRef.current = false;

            if (isConversationModeRef.current) {
              console.log('ğŸ”„ AI è¯´å®Œï¼Œç»§ç»­ç›‘å¬...');
              hasSpeechRef.current = false;
              audioProcessorRef.current?.resetVADState();
              if (!isListeningRef.current) {
                startListeningRef.current();
              }
            }
          } else {
            setTimeout(checkPlaybackDone, 200);
          }
        };
        setTimeout(checkPlaybackDone, 200);
      },

      onResponseDone: (usage) => {
        if (usage) {
          console.log('ğŸ“Š Token ä½¿ç”¨:', usage);
        }
      },

      onError: (err) => {
        setError(`API é”™è¯¯: ${err.message}`);
        setIsResponding(false);
      },
    });
  }, [addMessage]);

  // åˆå§‹åŒ– effect
  useEffect(() => {
    const defaultVoice = process.env.REACT_APP_DEFAULT_VOICE || 'male-qn-qingse';
    setSelectedVoice(defaultVoice);

    // åªåˆå§‹åŒ– AudioProcessor
    audioProcessorRef.current = new AudioProcessor();
    audioProcessorRef.current.setVADCallbacks({
      onSpeechStart: () => handleSpeechStartRef.current(),
      onSpeechEnd: () => handleSpeechEndRef.current(),
      onVolumeChange: (vol) => setVolume(vol),
    });

    return () => {
      realtimeRef.current?.disconnect();
      audioProcessorRef.current?.destroy();
    };
  }, []);

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages, streamingText]);

  // è‡ªåŠ¨æ¸…é™¤é”™è¯¯
  useEffect(() => {
    if (error) {
      const timer = setTimeout(() => setError(null), 5000);
      return () => clearTimeout(timer);
    }
  }, [error]);

  // ==================== è¿æ¥æ§åˆ¶ ====================
  const handleConnect = async () => {
    if (connectionStatus === 'connecting') return;

    // éªŒè¯ API Key
    if (!apiKey.trim()) {
      setError('è¯·è¾“å…¥ API Key');
      setShowSettings(true);
      return;
    }

    setConnectionStatus('connecting');
    setError(null);

    try {
      // åˆå§‹åŒ–æˆ–é‡æ–°åˆå§‹åŒ–æœåŠ¡
      realtimeRef.current = new RealtimeService({
        apiKey: apiKey.trim(),
        voice: selectedVoice,
        instructions: systemPrompt,
      });
      setupRealtimeCallbacks();

      await realtimeRef.current.connect();
    } catch (err: any) {
      setConnectionStatus('error');
      setError('è¿æ¥å¤±è´¥: ' + err.message);
    }
  };

  const handleDisconnect = () => {
    // é€€å‡ºå¯¹è¯æ¨¡å¼
    isConversationModeRef.current = false;
    setIsConversationMode(false);
    stopListening();

    realtimeRef.current?.disconnect();
    audioProcessorRef.current?.stopPlayback();
    setConnectionStatus('disconnected');
    setIsResponding(false);
  };

  // ==================== è¯­éŸ³è¾“å…¥ï¼ˆå¯¹è¯æ¨¡å¼åˆ‡æ¢ï¼‰ ====================
  const handleVoiceInput = async () => {
    // å¦‚æœæœªè¿æ¥ï¼Œå…ˆè¿æ¥
    if (!realtimeRef.current?.isConnectedState()) {
      await handleConnect();
      // ç­‰å¾…è¿æ¥å®Œæˆ
      await new Promise((resolve) => setTimeout(resolve, 500));
      if (!realtimeRef.current?.isConnectedState()) {
        return;
      }
    }

    if (isConversationMode) {
      // é€€å‡ºå¯¹è¯æ¨¡å¼
      console.log('ğŸ›‘ é€€å‡ºå¯¹è¯æ¨¡å¼');
      isConversationModeRef.current = false;
      setIsConversationMode(false);

      // åœæ­¢ç›‘å¬
      stopListening();

      // æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒºï¼ˆä¸æäº¤ï¼Œé¿å…ç©ºæ•°æ®é”™è¯¯ï¼‰
      realtimeRef.current?.clearAudioBuffer();

      // åœæ­¢ AI æ’­æ”¾
      if (isResponding) {
        isInterruptedRef.current = true;
        audioProcessorRef.current?.stopPlayback();
        realtimeRef.current?.interrupt();
        setIsResponding(false);
        setStreamingText('');
        streamingTextRef.current = '';
      }
    } else {
      // è¿›å…¥å¯¹è¯æ¨¡å¼
      console.log('ğŸ™ï¸ è¿›å…¥å¯¹è¯æ¨¡å¼');

      // å¦‚æœ AI æ­£åœ¨è¯´è¯ï¼Œæ‰“æ–­å®ƒ
      if (isResponding) {
        isInterruptedRef.current = true;
        audioProcessorRef.current?.stopPlayback();
        realtimeRef.current?.interrupt();
        setIsResponding(false);
        setStreamingText('');
        streamingTextRef.current = '';
      }

      // è®¾ç½®å¯¹è¯æ¨¡å¼
      isConversationModeRef.current = true;
      setIsConversationMode(true);

      // å¼€å§‹ç›‘å¬
      await startListening();
      setError(null);
    }
  };

  // ==================== æ‰“æ–­ ====================
  const handleInterrupt = () => {
    // è®¾ç½®æ‰“æ–­æ ‡å¿—ï¼Œå¿½ç•¥åç»­æ”¶åˆ°çš„éŸ³é¢‘å’Œæ–‡æœ¬æ•°æ®
    isInterruptedRef.current = true;
    // åœæ­¢æœ¬åœ°éŸ³é¢‘æ’­æ”¾
    audioProcessorRef.current?.stopPlayback();
    // æ¸…ç©ºéŸ³é¢‘è¾“å…¥ç¼“å†²åŒº
    realtimeRef.current?.interrupt();
    // æ¸…ç©ºæµå¼æ–‡æœ¬æ˜¾ç¤º
    setStreamingText('');
    streamingTextRef.current = '';
    // éšè—æ‰“æ–­æŒ‰é’®
    setIsResponding(false);
  };

  // ==================== éŸ³è‰²åˆ‡æ¢ ====================
  const handleVoiceChange = (voiceId: string) => {
    setSelectedVoice(voiceId);
    if (connectionStatus === 'connected') {
      realtimeRef.current?.updateSession({ voice: voiceId });
    }
  };

  // ==================== æ¸…ç©ºå¯¹è¯ ====================
  const handleClearChat = () => {
    setMessages([]);
    setStreamingText('');
  };

  // ==================== æ¸²æŸ“ ====================
  const isConnected = connectionStatus === 'connected';

  return (
    <div className="app">
      {/* å¤´éƒ¨ */}
      <header className="header">
        <div className="header-left">
          <h1>æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹</h1>
          <span className="version-tag">Realtime API</span>
        </div>
        <div className="header-right">
          <button
            className="btn btn-settings"
            onClick={() => setShowSettings(!showSettings)}
            title="è®¾ç½®"
          >
            âš™ï¸
          </button>
          <span className={`connection-status ${connectionStatus}`}>
            {connectionStatus === 'connected' && 'â— å·²è¿æ¥'}
            {connectionStatus === 'connecting' && 'â—‹ è¿æ¥ä¸­...'}
            {connectionStatus === 'disconnected' && 'â—‹ æœªè¿æ¥'}
            {connectionStatus === 'error' && 'â— è¿æ¥é”™è¯¯'}
          </span>
          {isConnected ? (
            <button className="btn btn-disconnect" onClick={handleDisconnect}>
              æ–­å¼€è¿æ¥
            </button>
          ) : (
            <button
              className="btn btn-connect"
              onClick={handleConnect}
              disabled={connectionStatus === 'connecting'}
            >
              {connectionStatus === 'connecting' ? 'è¿æ¥ä¸­...' : 'è¿æ¥'}
            </button>
          )}
        </div>
      </header>

      {/* è®¾ç½®é¢æ¿ */}
      {showSettings && (
        <div className="settings-panel">
          <div className="settings-header">
            <h3>è®¾ç½®</h3>
            <button className="btn-close" onClick={() => setShowSettings(false)}>Ã—</button>
          </div>

          <div className="settings-content">
            <div className="setting-item">
              <label>API Key</label>
              <input
                type="password"
                value={apiKey}
                onChange={(e) => setApiKey(e.target.value)}
                placeholder="è¾“å…¥ MiniMax API Key"
                disabled={isConnected}
              />
              {!apiKey && <span className="setting-hint">å¿…å¡«ï¼Œç”¨äºè¿æ¥ MiniMax Realtime API</span>}
            </div>

            <div className="setting-item">
              <label>äººè®¾æç¤ºè¯ (System Prompt)</label>
              <textarea
                value={systemPrompt}
                onChange={(e) => setSystemPrompt(e.target.value)}
                placeholder="è¾“å…¥ AI åŠ©æ‰‹çš„äººè®¾å’Œè¡Œä¸ºæŒ‡å¯¼..."
                rows={8}
                disabled={isConnected}
              />
              <span className="setting-hint">
                {isConnected ? 'æ–­å¼€è¿æ¥åå¯ä¿®æ”¹' : 'å®šä¹‰ AI åŠ©æ‰‹çš„è§’è‰²ã€æ€§æ ¼å’Œè¡Œä¸ºæ–¹å¼'}
              </span>
            </div>

            <div className="setting-actions">
              <button
                className="btn btn-reset"
                onClick={() => setSystemPrompt(DEFAULT_SYSTEM_PROMPT)}
                disabled={isConnected}
              >
                æ¢å¤é»˜è®¤
              </button>
            </div>
          </div>
        </div>
      )}

      {/* èŠå¤©åŒºåŸŸ */}
      <div className="chat-container">
        <div className="messages-container">
          {messages.length === 0 && !streamingText ? (
            <div className="empty-state">
              <div className="empty-icon">ğŸ‘‹</div>
              <h2>æ¬¢è¿ä½¿ç”¨ MiniMax æ™ºèƒ½è¯­éŸ³åŠ©æ‰‹</h2>
              <p>ä½¿ç”¨ Realtime API å®ç°ä½å»¶è¿Ÿè¯­éŸ³å¯¹è¯</p>
              <div className="features">
                <div className="feature">
                  <span className="feature-icon">ğŸ¤</span>
                  <span>å®æ—¶è¯­éŸ³è¯†åˆ«</span>
                </div>
                <div className="feature">
                  <span className="feature-icon">ğŸ¤–</span>
                  <span>æ™ºèƒ½å¯¹è¯</span>
                </div>
                <div className="feature">
                  <span className="feature-icon">ğŸ”Š</span>
                  <span>æµå¼è¯­éŸ³åˆæˆ</span>
                </div>
              </div>
              {!isConnected && (
                <button className="btn btn-primary btn-large" onClick={handleConnect}>
                  å¼€å§‹ä½¿ç”¨
                </button>
              )}
            </div>
          ) : (
            <>
              {messages.map((message) => (
                <div key={message.id} className={`message ${message.role}`}>
                  <div className="message-bubble">
                    <div className="message-content">
                      {message.content}
                      {message.isAudio && <span className="audio-indicator">ğŸ¤</span>}
                    </div>
                    <div className="message-time">
                      {message.timestamp.toLocaleTimeString('zh-CN', {
                        hour: '2-digit',
                        minute: '2-digit',
                      })}
                    </div>
                  </div>
                </div>
              ))}

              {/* AI å“åº”æµå¼æ˜¾ç¤º */}
              {streamingText && (
                <div className="message assistant">
                  <div className="message-bubble streaming">
                    <div className="message-content">
                      {streamingText}
                      <span className="streaming-cursor">â–‹</span>
                    </div>
                  </div>
                </div>
              )}

              <div ref={messagesEndRef} />
            </>
          )}
        </div>

        {/* é”™è¯¯æç¤º */}
        {error && (
          <div className="error-message" onClick={clearError}>
            {error}
            <span className="error-close">Ã—</span>
          </div>
        )}

        {/* è®¾ç½®æ  */}
        <div className="settings-bar">
          <div className="voice-selector">
            <label>ğŸ¤ éŸ³è‰²ï¼š</label>
            <select value={selectedVoice} onChange={(e) => handleVoiceChange(e.target.value)}>
              {VOICE_OPTIONS.map((voice) => (
                <option key={voice.id} value={voice.id}>
                  {voice.name}
                </option>
              ))}
            </select>
          </div>
          {messages.length > 0 && (
            <button className="btn btn-clear" onClick={handleClearChat}>
              ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯
            </button>
          )}
        </div>

        {/* è¯­éŸ³è¾“å…¥åŒºåŸŸ */}
        <div className="input-container">
          <div className="action-buttons">
            {isResponding && !isConversationMode && (
              <button type="button" className="btn btn-interrupt" onClick={handleInterrupt} title="æ‰“æ–­">
                â¹ï¸
              </button>
            )}

            <button
              type="button"
              className={`btn btn-voice ${isConversationMode ? 'conversation-mode' : ''} ${isListening ? 'listening' : ''}`}
              onClick={handleVoiceInput}
              disabled={connectionStatus === 'connecting'}
              title={isConversationMode ? 'ç»“æŸå¯¹è¯' : 'å¼€å§‹å¯¹è¯'}
              style={isListening ? { boxShadow: `0 0 ${10 + volume * 30}px rgba(59, 130, 246, ${0.5 + volume * 0.5})` } : undefined}
            >
              {isConversationMode ? (isListening ? 'ğŸ‘‚' : 'ğŸ’¬') : 'ğŸ¤'}
            </button>

            {isResponding && !isConversationMode && (
              <div style={{ width: 56 }} /> /* å ä½ï¼Œä¿æŒæŒ‰é’®å±…ä¸­ */
            )}
          </div>
        </div>

        {/* çŠ¶æ€æ  */}
        <div className="status-bar">
          <div className="status-item">
            <span className={`status-dot ${isConnected ? 'active' : ''}`}></span>
            <span>Realtime API</span>
          </div>
          {isConversationMode && (
            <div className="status-item conversation">
              <span className="status-dot pulse"></span>
              <span>å¯¹è¯æ¨¡å¼</span>
            </div>
          )}
          {isListening && (
            <div className="status-item recording">
              <span className="status-dot pulse"></span>
              <span>æ­£åœ¨å¬...</span>
            </div>
          )}
          {isResponding && (
            <div className="status-item">
              <span className="status-dot active"></span>
              <span>AI å›å¤ä¸­...</span>
            </div>
          )}
        </div>
      </div>
    </div>
  );
};

export default App;
